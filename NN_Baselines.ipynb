{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "NN Baselines.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "922cf88f"
      },
      "source": [
        "# NN Baselines"
      ],
      "id": "922cf88f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bd9fe8a"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string"
      ],
      "id": "7bd9fe8a",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2CjU95KGR2e",
        "outputId": "d7d73b1e-dd3a-4e62-f838-c281dbdef9a4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('gdrive')\n",
        "import string"
      ],
      "id": "o2CjU95KGR2e",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj3VxtL1ydFb",
        "outputId": "399f8ef9-b375-4707-e042-aacc1d57ffc7"
      },
      "source": [
        "!nvidia-smi"
      ],
      "id": "wj3VxtL1ydFb",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Nov 27 07:03:25 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c68dcd36",
        "outputId": "10fb6a5d-ae0a-4fd8-d5ba-b4b803d8d5e0"
      },
      "source": [
        "cd /content/gdrive/MyDrive/College/Semester5/NLP/project"
      ],
      "id": "c68dcd36",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/College/Semester5/NLP/project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x81X0dQmymPJ",
        "outputId": "918237d9-30e9-4c7e-c584-34e83dd9cafa"
      },
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "id": "x81X0dQmymPJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fkt1BmxiGntz"
      },
      "source": [
        "# df_train = pd.read_csv(\"train.csv\")\n",
        "# df_train['author'] = df_train['author'].replace(np.nan, \"<NO_AUTHOR>\")\n",
        "# df_train['title'] =  df_train['title'].replace(np.nan, \"<NO_TITLE>\")\n",
        "# df_train['text'] =   df_train['text'].replace(np.nan, \"<NO_TEXT>\")\n",
        "# for i, j in df_train.iterrows():\n",
        "#     df_train.at[i, 'text'] = j['author']+\" | \"+j['title'] +\" | \"+ j['text']\n",
        "# def punctuation_removal(text):\n",
        "#     all_list = [char for char in text if char not in string.punctuation]\n",
        "#     clean_str = ''.join(all_list)\n",
        "#     return clean_str\n",
        "# df_train['text'] = df_train['text'].apply(punctuation_removal)\n",
        "# stop = stopwords.words('english')\n",
        "# df_train['text'] = df_train['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "# df_train = df_train.sample(frac=1)"
      ],
      "id": "Fkt1BmxiGntz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBHRsRQdITi-"
      },
      "source": [
        "# del df_train['author']\n",
        "# del df_train['title']\n",
        "# del df_train['id']"
      ],
      "id": "tBHRsRQdITi-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2NPvidryrrX"
      },
      "source": [
        "# df = df_train.sample(frac=1)"
      ],
      "id": "l2NPvidryrrX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUxsDOqqJDno"
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# train_x, valid_x, train_y, valid_y = train_test_split(df['text'], df['label'], test_size = 0.2)"
      ],
      "id": "kUxsDOqqJDno",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf8zS9plz2lK"
      },
      "source": [
        "# import pickle\n",
        "# file_to_store = open(\"split.pkl\", \"wb\")\n",
        "# pickle.dump((train_x, valid_x, train_y, valid_y), file_to_store)"
      ],
      "id": "zf8zS9plz2lK",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSMw1xdb6Lj6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "file = open(\"split.pkl\", 'rb')\n",
        "train_x, valid_x, train_y, valid_y = pickle.load(file)"
      ],
      "id": "SSMw1xdb6Lj6",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f4b65ee"
      },
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "\n",
        "import pandas, numpy, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers"
      ],
      "id": "2f4b65ee",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8DtK3Y5H0s2"
      },
      "source": [
        "from tensorflow.keras import optimizers"
      ],
      "id": "M8DtK3Y5H0s2",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a66fdc8"
      },
      "source": [
        "# encoder = preprocessing.LabelEncoder()\n",
        "# train_y = encoder.fit_transform(train_y)\n",
        "# valid_y = encoder.fit_transform(valid_y)"
      ],
      "id": "3a66fdc8",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3c3ae1a"
      },
      "source": [
        "trainDF = pd.DataFrame()\n",
        "trainDF['text'] = np.concatenate([train_x, valid_x])\n",
        "trainDF['labels'] = np.concatenate([train_y, valid_y])"
      ],
      "id": "b3c3ae1a",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34902f5d"
      },
      "source": [
        "embeddings_index = {}\n",
        "for i, line in enumerate(open('/content/gdrive/MyDrive/Amazon/productner/data/glove.6B.100d.txt')):\n",
        "    values = line.split()\n",
        "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
        "\n",
        "token = text.Tokenizer()\n",
        "token.fit_on_texts(trainDF['text'])\n",
        "word_index = token.word_index\n",
        "\n",
        "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
        "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=70)\n",
        "\n",
        "embedding_matrix = numpy.zeros((len(word_index) + 1, 100))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "id": "34902f5d",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dae84a7"
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "\n",
        "    classifier.fit(feature_vector_train, label, epochs=3)\n",
        "\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    pred =[]\n",
        "    for i in predictions:\n",
        "        pred.append([np.round(i[0])])\n",
        "    predictions = pred\n",
        "    return metrics.accuracy_score(predictions, valid_y), metrics.precision_score(predictions, valid_y),metrics.recall_score(predictions, valid_y),metrics.f1_score(predictions, valid_y)"
      ],
      "id": "0dae84a7",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdf2acfc",
        "outputId": "2623fade-5155-4659-9704-003df1478989"
      },
      "source": [
        "def create_cnn():\n",
        "\n",
        "    input_layer = layers.Input((70, ))\n",
        "\n",
        "    embedding_layer = layers.Embedding(len(word_index) + 1, 100, weights=[embedding_matrix], trainable=True)(input_layer)\n",
        "    # embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
        "\n",
        "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
        "\n",
        "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
        "\n",
        "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(pooling_layer)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
        "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
        "    \n",
        "    return model\n",
        "\n",
        "classifier = create_cnn()\n",
        "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
        "\n",
        "print (\"accuracy:-\", accuracy[0])\n",
        "print (\"precision:-\", accuracy[1])\n",
        "print (\"recall:-\", accuracy[2])\n",
        "print (\"f1 score:-\", accuracy[3])\n"
      ],
      "id": "bdf2acfc",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "520/520 [==============================] - 16s 30ms/step - loss: 0.2718\n",
            "Epoch 2/3\n",
            "520/520 [==============================] - 16s 30ms/step - loss: 0.0805\n",
            "Epoch 3/3\n",
            "520/520 [==============================] - 16s 30ms/step - loss: 0.0219\n",
            "accuracy:- 0.9504807692307692\n",
            "precision:- 0.968019093078759\n",
            "recall:- 0.9358560221504384\n",
            "f1 score:- 0.9516658845612389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ygM1h3nHuRJ",
        "outputId": "058ac88f-a1f1-41e2-f498-c917bfbf78e8"
      },
      "source": [
        "def create_rcnn():\n",
        "\n",
        "    input_layer = layers.Input((70, ))\n",
        "\n",
        "    embedding_layer = layers.Embedding(len(word_index) + 1, 100, weights=[embedding_matrix], trainable=False)(input_layer)\n",
        "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
        "\n",
        "    rnn_layer = layers.Bidirectional(layers.LSTM(50, return_sequences=True))(embedding_layer)\n",
        "    # rnn_layer = layers.GRU(50, return_sequences=True)(embedding_layer)\n",
        "\n",
        "\n",
        "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
        "\n",
        "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
        "    \n",
        "    output_layer1 = layers.Dense(50, activation=\"relu\")(pooling_layer)\n",
        "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
        "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
        "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
        "    \n",
        "    return model\n",
        "\n",
        "classifier = create_rcnn()\n",
        "\n",
        "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
        "print (\"accuracy:-\", accuracy[0])\n",
        "print (\"precision:-\", accuracy[1])\n",
        "print (\"recall:-\", accuracy[2])\n",
        "print (\"f1 score:-\", accuracy[3])\n"
      ],
      "id": "8ygM1h3nHuRJ",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "520/520 [==============================] - 4s 6ms/step - loss: 0.4652\n",
            "Epoch 2/3\n",
            "520/520 [==============================] - 3s 6ms/step - loss: 0.2590\n",
            "Epoch 3/3\n",
            "520/520 [==============================] - 3s 6ms/step - loss: 0.2117\n",
            "accuracy:- 0.926923076923077\n",
            "precision:- 0.9665871121718377\n",
            "recall:- 0.896414342629482\n",
            "f1 score:- 0.9301791456132292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9DiIk9oKxNY",
        "outputId": "45d47690-546f-4179-b7d1-c1126df19170"
      },
      "source": [
        "def create_bidirectional_rnn():\n",
        "\n",
        "    input_layer = layers.Input((70, ))\n",
        "\n",
        "    embedding_layer = layers.Embedding(len(word_index) + 1, 100, weights=[embedding_matrix], trainable=True)(input_layer)\n",
        "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
        "\n",
        "    lstm_layer = layers.Bidirectional(layers.GRU(100))(embedding_layer)\n",
        "\n",
        "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
        "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
        "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
        "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
        "    \n",
        "    return model\n",
        "\n",
        "classifier = create_bidirectional_rnn()\n",
        "\n",
        "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
        "print (\"accuracy:-\", accuracy[0])\n",
        "print (\"precision:-\", accuracy[1])\n",
        "print (\"recall:-\", accuracy[2])\n",
        "print (\"f1 score:-\", accuracy[3])\n"
      ],
      "id": "F9DiIk9oKxNY",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "520/520 [==============================] - 33s 56ms/step - loss: 0.3582\n",
            "Epoch 2/3\n",
            "520/520 [==============================] - 29s 55ms/step - loss: 0.1417\n",
            "Epoch 3/3\n",
            "520/520 [==============================] - 29s 55ms/step - loss: 0.0672\n",
            "accuracy:- 0.9533653846153847\n",
            "precision:- 0.9646778042959427\n",
            "recall:- 0.9439514245679589\n",
            "f1 score:- 0.9542020774315393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyv_6PPpMTLG",
        "outputId": "278a0000-1ca6-43fa-b2bb-1b375fcdb62f"
      },
      "source": [
        "def create_rnn_gru():\n",
        "\n",
        "    input_layer = layers.Input((70, ))\n",
        "\n",
        "    embedding_layer = layers.Embedding(len(word_index) + 1, 100, weights=[embedding_matrix], trainable=False)(input_layer)\n",
        "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
        "\n",
        "    lstm_layer = layers.GRU(100)(embedding_layer)\n",
        "\n",
        "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
        "    # output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
        "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
        "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
        "    \n",
        "    return model\n",
        "\n",
        "classifier = create_rnn_gru()\n",
        "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
        "print (\"accuracy:-\", accuracy[0])\n",
        "print (\"precision:-\", accuracy[1])\n",
        "print (\"recall:-\", accuracy[2])\n",
        "print (\"f1 score:-\", accuracy[3])\n"
      ],
      "id": "xyv_6PPpMTLG",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "520/520 [==============================] - 12s 19ms/step - loss: 0.4013\n",
            "Epoch 2/3\n",
            "520/520 [==============================] - 10s 19ms/step - loss: 0.2245\n",
            "Epoch 3/3\n",
            "520/520 [==============================] - 10s 19ms/step - loss: 0.1798\n",
            "accuracy:- 0.9348557692307692\n",
            "precision:- 0.9274463007159904\n",
            "recall:- 0.9422890397672163\n",
            "f1 score:- 0.93480875631465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs6TaUWZMYAt",
        "outputId": "bf67de83-3791-4077-d6d6-82c762f184e0"
      },
      "source": [
        "def create_rnn_lstm():\n",
        "    input_layer = layers.Input((70, ))\n",
        "\n",
        "    embedding_layer = layers.Embedding(len(word_index) + 1, 100, weights=[embedding_matrix], trainable=False)(input_layer)\n",
        "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
        "\n",
        "\n",
        "    lstm_layer = layers.LSTM(100)(embedding_layer)\n",
        "\n",
        "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
        "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
        "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
        "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
        "    \n",
        "    return model\n",
        "\n",
        "classifier = create_rnn_lstm()\n",
        "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
        "print (\"accuracy:-\", accuracy[0])\n",
        "print (\"precision:-\", accuracy[1])\n",
        "print (\"recall:-\", accuracy[2])\n",
        "print (\"f1 score:-\", accuracy[3])\n"
      ],
      "id": "xs6TaUWZMYAt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "520/520 [==============================] - 12s 20ms/step - loss: 0.4303\n",
            "Epoch 2/3\n",
            "520/520 [==============================] - 10s 20ms/step - loss: 0.2790\n",
            "Epoch 3/3\n",
            "520/520 [==============================] - 10s 20ms/step - loss: 0.2169\n",
            "accuracy:- 0.9350961538461539\n",
            "precision:- 0.9322195704057279\n",
            "recall:- 0.9384911100432485\n",
            "f1 score:- 0.9353448275862069\n"
          ]
        }
      ]
    }
  ]
}