{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HCAN_Deploy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eqpskII9k9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d85846e-2b8a-4011-ceff-c90dbdb2047c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R7yoMOYkNFu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b81b45a2-7be6-4589-8164-0c368f2b5f60"
      },
      "source": [
        "cd /content/gdrive/MyDrive/College/Semester5/NLP/project"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/College/Semester5/NLP/project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak07QYnM-QQC"
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import initializers, regularizers, constraints\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "\n",
        "class Attention(Layer):\n",
        "    def __init__(self, step_dim,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        \"\"\"\n",
        "        Keras Layer that implements an Attention mechanism for temporal data.\n",
        "        Supports Masking.\n",
        "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
        "        # Input shape\n",
        "            3D tensor with shape: `(samples, steps, features)`.\n",
        "        # Output shape\n",
        "            2D tensor with shape: `(samples, features)`.\n",
        "        :param kwargs:\n",
        "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "        The dimensions are inferred based on the output shape of the RNN.\n",
        "        Example:\n",
        "            # 1\n",
        "            model.add(LSTM(64, return_sequences=True))\n",
        "            model.add(Attention())\n",
        "            # next add a Dense layer (for classification/regression) or whatever...\n",
        "            # 2\n",
        "            hidden = LSTM(64, return_sequences=True)(words)\n",
        "            sentence = Attention()(hidden)\n",
        "            # next add a Dense layer (for classification/regression) or whatever...\n",
        "        \"\"\"\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(name='{}_W'.format(self.name),\n",
        "                                 shape=(input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(name='{}_b'.format(self.name),\n",
        "                                     shape=(input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        e = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))  # e = K.dot(x, self.W)\n",
        "        if self.bias:\n",
        "            e += self.b\n",
        "        e = K.tanh(e)\n",
        "\n",
        "        a = K.exp(e)\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number Îµ to the sum.\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "        a = K.expand_dims(a)\n",
        "\n",
        "        c = K.sum(a * x, axis=1)\n",
        "        return c\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], self.features_dim\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNSzBsq5-pd9"
      },
      "source": [
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Embedding, Dense, Bidirectional, TimeDistributed\n",
        "# from keras.layers import CuDNNGRU\n",
        "from keras.layers import GRU\n",
        "\n",
        "class HCAN(Model):\n",
        "    def __init__(self,\n",
        "                 maxlen_sentence,\n",
        "                 maxlen_word,\n",
        "                 max_features,\n",
        "                 embedding_dims,\n",
        "                 class_num=1,\n",
        "                 last_activation='sigmoid'):\n",
        "        super(HCAN, self).__init__()\n",
        "        self.maxlen_sentence = maxlen_sentence\n",
        "        self.maxlen_word = maxlen_word\n",
        "        self.max_features = max_features\n",
        "        self.embedding_dims = embedding_dims\n",
        "        self.class_num = class_num\n",
        "        self.last_activation = last_activation\n",
        "        # Word part\n",
        "        input_word = Input(shape=(self.maxlen_word,))\n",
        "        x_word = Embedding(self.max_features, self.embedding_dims, input_length=self.maxlen_word)(input_word)\n",
        "        x_word = layers.Convolution1D(100, 10, activation=\"relu\", padding = 'same')(x_word)\n",
        "        # x_word = layers.GlobalMaxPool1D()(x_word)\n",
        "\n",
        "        x_word = Bidirectional(GRU(128, return_sequences=True))(x_word)  # LSTM or GRU\n",
        "        x_word = Attention(self.maxlen_word)(x_word)\n",
        "        model_word = Model(input_word, x_word)\n",
        "        # Sentence part\n",
        "        self.word_encoder_att = TimeDistributed(model_word)\n",
        "        self.sentence_encoder = Bidirectional(GRU(128, return_sequences=True))  # LSTM or GRU\n",
        "        self.sentence_att = Attention(self.maxlen_sentence)\n",
        "        # Output part\n",
        "        self.classifier = Dense(self.class_num, activation=self.last_activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if len(inputs.get_shape()) != 3:\n",
        "            raise ValueError('The rank of inputs of HAN must be 3, but now is %d' % len(inputs.get_shape()))\n",
        "        if inputs.get_shape()[1] != self.maxlen_sentence:\n",
        "            raise ValueError('The maxlen_sentence of inputs of HAN must be %d, but now is %d' % (self.maxlen_sentence, inputs.get_shape()[1]))\n",
        "        if inputs.get_shape()[2] != self.maxlen_word:\n",
        "            raise ValueError('The maxlen_word of inputs of HAN must be %d, but now is %d' % (self.maxlen_word, inputs.get_shape()[2]))\n",
        "        x_sentence = self.word_encoder_att(inputs)\n",
        "        x_sentence = self.sentence_encoder(x_sentence)\n",
        "        x_sentence = self.sentence_att(x_sentence)\n",
        "        output = self.classifier(x_sentence)\n",
        "        return output\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YQSKK2i_qpb"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RudDSyTt1FJT"
      },
      "source": [
        "## **Deploying from Colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTtIInXo35sy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d1dc47-2a45-44ac-cdf4-d15ef7f2af89"
      },
      "source": [
        "cd /content/gdrive/MyDrive/College/Semester5/NLP/project/Final"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/College/Semester5/NLP/project/Final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbwFal5v42Wo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce7644ba-17ec-478d-fb7f-fe3db1300fa1"
      },
      "source": [
        "!pip install flask_ngrok"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask_ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (1.1.4)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_ngrok) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (1.24.3)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Sm1fmzb5ZPu"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import joblib\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Embedding, Dense, Bidirectional, TimeDistributed\n",
        "from keras.layers import GRU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "import pandas as pd\n",
        "import numpy\n",
        "from keras.preprocessing import text, sequence\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras import layers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import initializers, regularizers, constraints\n",
        "from tensorflow.keras.layers import Layer\n",
        "import os\n",
        "import sys\n",
        "import joblib"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T24wFVqK1diZ",
        "outputId": "1d5e1a43-f6e6-4b2b-e0d2-e19ce5bf600d"
      },
      "source": [
        "import flask\n",
        "from flask import Flask,render_template,url_for,request\n",
        "import joblib\n",
        "from flask_ngrok import run_with_ngrok\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "import os\n",
        "@app.route('/')\n",
        "def home():\n",
        "  return render_template('home.html')\n",
        "\n",
        "@app.route('/predict',methods=['POST'])\n",
        "def predict():\n",
        "  max_features = 5000\n",
        "  maxlen_sentence = 16\n",
        "  maxlen_word = 25\n",
        "  batch_size = 32\n",
        "  embedding_dims = 50\n",
        "  cwd = os.getcwd()\n",
        "  print(cwd)\n",
        "  model2 = HCAN(maxlen_sentence, maxlen_word, max_features, embedding_dims)\n",
        "  model2.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
        "  token = joblib.load(\"token.sav\")\n",
        "  model2.load_weights('hcan_final_run')\n",
        "  if request.method == 'POST':\n",
        "    message = request.form['message']\n",
        "    data = numpy.array([message])\n",
        "    data = sequence.pad_sequences(token.texts_to_sequences(data), maxlen=maxlen_sentence * maxlen_word)\n",
        "    data = data.reshape((len(data), maxlen_sentence, maxlen_word))\n",
        "    my_prediction = model2.predict(data)\n",
        "\n",
        "  if my_prediction[0][0] > 0.5:\n",
        "    preds = 1\n",
        "  else:\n",
        "    preds = 0\n",
        "  return render_template('result.html', prediction = preds)\n",
        " \n",
        "app.run()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://5b3e-35-184-80-233.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [28/Nov/2021 01:24:40] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [28/Nov/2021 01:24:41] \"\u001b[33mGET /static/static/styles.css HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [28/Nov/2021 01:24:41] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [28/Nov/2021 01:25:09] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [28/Nov/2021 01:25:09] \"\u001b[33mGET /static/static/styles.css HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/College/Semester5/NLP/project/Final\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [28/Nov/2021 01:25:45] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [28/Nov/2021 01:25:45] \"\u001b[33mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/College/Semester5/NLP/project/Final\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).sentence_att.attention_1_W\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).sentence_att.attention_1_b\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).classifier.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).classifier.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).sentence_encoder.forward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).sentence_encoder.forward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).sentence_encoder.forward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).sentence_encoder.backward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).sentence_encoder.backward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).sentence_encoder.backward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).sentence_att.attention_1_W\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).sentence_att.attention_1_b\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).classifier.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).classifier.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).sentence_encoder.forward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).sentence_encoder.forward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).sentence_encoder.forward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).sentence_encoder.backward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).sentence_encoder.backward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).sentence_encoder.backward_layer.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [28/Nov/2021 01:27:34] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [28/Nov/2021 01:27:34] \"\u001b[33mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAVTetfKEU_L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}